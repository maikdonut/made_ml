{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjfoWcBJl4me"
   },
   "source": [
    "## Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT4Nv5jUl4mh"
   },
   "source": [
    "### Part 3. Poetry generation\n",
    "\n",
    "Let's try to generate some poetry using RNNs. \n",
    "\n",
    "You have several choices here: \n",
    "\n",
    "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
    "\n",
    "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
    "\n",
    "* Some other text source, if it will be approved by the course staff.\n",
    "\n",
    "Text generation can be designed in several steps:\n",
    "    \n",
    "1. Data loading.\n",
    "2. Dictionary generation.\n",
    "3. Data preprocessing.\n",
    "4. Model (neural network) training.\n",
    "5. Text generation (model evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xKZqIFpil4mi"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG2ldJ20l4mj"
   },
   "source": [
    "### Data loading: Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u9iVoaxl4mj"
   },
   "source": [
    "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "abWT6zawl4mk"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('sonnets.txt'):\n",
    "    !wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks_basic/lab02_deep_learning/sonnets.txt\n",
    "\n",
    "with open('sonnets.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START : TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElqOUcdWLrsE",
    "outputId": "a6baf028-520a-4af4-a671-133390f47415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  From fairest creatures we desire increase,\\n',\n",
       " \"  That thereby beauty's rose might never die,\\n\",\n",
       " '  But as the riper should by time decease,\\n',\n",
       " '  His tender heir might bear his memory:\\n',\n",
       " '  But thou, contracted to thine own bright eyes,\\n',\n",
       " \"  Feed'st thy light's flame with self-substantial fuel,\\n\",\n",
       " '  Making a famine where abundance lies,\\n',\n",
       " '  Thy self thy foe, to thy sweet self too cruel:\\n',\n",
       " \"  Thou that art now the world's fresh ornament,\\n\",\n",
       " '  And only herald to the gaudy spring,\\n',\n",
       " '  Within thine own bud buriest thy content,\\n',\n",
       " \"  And tender churl mak'st waste in niggarding:\\n\",\n",
       " '    Pity the world, or else this glutton be,\\n',\n",
       " \"    To eat the world's due, by the grave and thee.\\n\",\n",
       " '\\n',\n",
       " '  II\\n',\n",
       " '\\n',\n",
       " '  When forty winters shall besiege thy brow,\\n',\n",
       " \"  And dig deep trenches in thy beauty's field,\\n\",\n",
       " \"  Thy youth's proud livery so gazed on now,\\n\",\n",
       " \"  Will be a tatter'd weed of small worth held:\\n\",\n",
       " '  Then being asked, where all thy beauty lies,\\n',\n",
       " '  Where all the treasure of thy lusty days;\\n',\n",
       " '  To say, within thine own deep sunken eyes,\\n',\n",
       " '  Were an all-eating shame, and thriftless praise.\\n',\n",
       " \"  How much more praise deserv'd thy beauty's use,\\n\",\n",
       " \"  If thou couldst answer 'This fair child of mine\\n\",\n",
       " \"  Shall sum my count, and make my old excuse,'\\n\",\n",
       " '  Proving his beauty by succession thine!\\n',\n",
       " '    This were to be new made when thou art old,\\n',\n",
       " \"    And see thy blood warm when thou feel'st it cold.\\n\",\n",
       " '\\n',\n",
       " '  III\\n',\n",
       " '\\n',\n",
       " '  Look in thy glass and tell the face thou viewest\\n',\n",
       " '  Now is the time that face should form another;\\n',\n",
       " '  Whose fresh repair if now thou not renewest,\\n',\n",
       " '  Thou dost beguile the world, unbless some mother.\\n',\n",
       " \"  For where is she so fair whose unear'd womb\\n\",\n",
       " '  Disdains the tillage of thy husbandry?\\n',\n",
       " '  Or who is he so fond will be the tomb,\\n',\n",
       " '  Of his self-love to stop posterity?\\n',\n",
       " \"  Thou art thy mother's glass and she in thee\\n\",\n",
       " '  Calls back the lovely April of her prime;\\n',\n",
       " '  So thou through windows of thine age shalt see,\\n',\n",
       " '  Despite of wrinkles this thy golden time.\\n',\n",
       " \"    But if thou live, remember'd not to be,\\n\",\n",
       " '    Die single and thine image dies with thee.\\n',\n",
       " '\\n',\n",
       " '  IV\\n',\n",
       " '\\n',\n",
       " '  Unthrifty loveliness, why dost thou spend\\n',\n",
       " \"  Upon thy self thy beauty's legacy?\\n\",\n",
       " \"  Nature's bequest gives nothing, but doth lend,\\n\",\n",
       " '  And being frank she lends to those are free:\\n',\n",
       " '  Then, beauteous niggard, why dost thou abuse\\n',\n",
       " '  The bounteous largess given thee to give?\\n',\n",
       " '  Profitless usurer, why dost thou use\\n',\n",
       " '  So great a sum of sums, yet canst not live?\\n',\n",
       " '  For having traffic with thy self alone,\\n',\n",
       " '  Thou of thy self thy sweet self dost deceive:\\n',\n",
       " '  Then how when nature calls thee to be gone,\\n',\n",
       " '  What acceptable audit canst thou leave?\\n',\n",
       " '    Thy unused beauty must be tombed with thee,\\n',\n",
       " \"    Which, used, lives th' executor to be.\\n\",\n",
       " '\\n',\n",
       " '  V\\n',\n",
       " '\\n',\n",
       " '  Those hours, that with gentle work did frame\\n',\n",
       " '  The lovely gaze where every eye doth dwell,\\n',\n",
       " '  Will play the tyrants to the very same\\n',\n",
       " '  And that unfair which fairly doth excel;\\n',\n",
       " '  For never-resting time leads summer on\\n',\n",
       " '  To hideous winter, and confounds him there;\\n',\n",
       " '  Sap checked with frost, and lusty leaves quite gone,\\n',\n",
       " \"  Beauty o'er-snowed and bareness every where:\\n\",\n",
       " \"  Then were not summer's distillation left,\\n\",\n",
       " '  A liquid prisoner pent in walls of glass,\\n',\n",
       " \"  Beauty's effect with beauty were bereft,\\n\",\n",
       " '  Nor it, nor no remembrance what it was:\\n',\n",
       " \"    But flowers distill'd, though they with winter meet,\\n\",\n",
       " '    Leese but their show; their substance still lives sweet.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '  VI\\n',\n",
       " '\\n',\n",
       " \"  Then let not winter's ragged hand deface,\\n\",\n",
       " \"  In thee thy summer, ere thou be distill'd:\\n\",\n",
       " '  Make sweet some vial; treasure thou some place\\n',\n",
       " \"  With beauty's treasure ere it be self-kill'd.\\n\",\n",
       " '  That use is not forbidden usury,\\n',\n",
       " '  Which happies those that pay the willing loan;\\n',\n",
       " \"  That's for thy self to breed another thee,\\n\",\n",
       " '  Or ten times happier, be it ten for one;\\n',\n",
       " '  Ten times thy self were happier than thou art,\\n',\n",
       " \"  If ten of thine ten times refigur'd thee:\\n\",\n",
       " '  Then what could death do if thou shouldst depart,\\n',\n",
       " '  Leaving thee living in posterity?\\n',\n",
       " \"    Be not self-will'd, for thou art much too fair\\n\",\n",
       " \"    To be death's conquest and make worms thine heir.\\n\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dog-dW47NSn_"
   },
   "source": [
    "As we can see sonnets have almost the same length, so let`s take a sample and find out the average len of one text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WN9UVxUjL2Jw",
    "outputId": "87b48300-1099-4721-ba81-d17b24c1c6fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649.6666666666666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''.join(text)\n",
    "sample = re.split('II|III|IV|V', text)[:6]\n",
    "np.mean([len(t) for t in sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LBT6Ff8BNjsX"
   },
   "outputs": [],
   "source": [
    "# so set SEQ_LEN as 650\n",
    "SEQ_LEN = 650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0aktGzIl4mk"
   },
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQdHufRTl4mk",
    "outputId": "4fb746aa-6c4f-4a7e-98bc-8443e4352e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "text = text.lower()\n",
    "# Your great code here\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GYqM2ITmKGK3"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a03iG7Knl4mm"
   },
   "source": [
    "Put all the characters, that you've seen in the text, into variable `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ALKbokQCl4mm"
   },
   "outputs": [],
   "source": [
    "tokens = sorted(set(text))\n",
    "assert len(tokens) == 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tonpUYOcl4mn"
   },
   "source": [
    "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "id": "FyQ-625Sl4mn"
   },
   "outputs": [],
   "source": [
    "# dict <index>:<char>\n",
    "idx_to_token = dict((i, c) for i, c in enumerate(tokens))\n",
    "# dict <char>:<index>\n",
    "token_to_idx = dict((c, i) for i, c in enumerate(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8AYCRKV0MxHj"
   },
   "outputs": [],
   "source": [
    "sequence = np.array([token_to_idx[char] for char in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWkoEO9ol4mn"
   },
   "source": [
    "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQo7Np_KRwUm"
   },
   "source": [
    "__Define some functions for nets training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QVtfb1Q0JrHO"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "def get_batches(sequence: np.array, batch_size = BATCH_SIZE, seq_len=SEQ_LEN):\n",
    "    '''\n",
    "    Generate batches from the sequence of indices for network training; \n",
    "    '''\n",
    "    total_size = batch_size * seq_len\n",
    "    n_batches = len(sequence)//total_size    \n",
    "    chunk = sequence[:n_batches * total_size]\n",
    "    chunk = chunk.reshape((batch_size, -1))\n",
    "    for n in range(0, chunk.shape[1], seq_len):\n",
    "        train = chunk[:, n:n+seq_len]\n",
    "        target = np.zeros_like(train)\n",
    "        try:\n",
    "            target[:, :-1], target[:, -1] = train[:, 1:], chunk[:, n+seq_len]\n",
    "        except IndexError:\n",
    "            target[:, :-1], target[:, -1] = train[:, 1:], chunk[:, 0]\n",
    "        yield train, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Uw134oZwR6sU"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence: np.array, n_labels: int):\n",
    "    '''\n",
    "    Converts encoded characters from integers to one-hot vectors\n",
    "    '''\n",
    "    ohe = np.zeros((np.multiply(*sequence.shape), n_labels), dtype=np.float32)    \n",
    "    ohe[np.arange(ohe.shape[0]), sequence.flatten()] = 1.    \n",
    "    ohe = ohe.reshape((*sequence.shape, n_labels))\n",
    "    return ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYQeZcb3l4mn"
   },
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdrlVh4Tl4mn"
   },
   "source": [
    "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
    "\n",
    "Let's use vanilla RNN, similar to the one created during the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU7bHrWkkpHG"
   },
   "source": [
    "__Did not implement__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSGDRmmFl4mo"
   },
   "source": [
    "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKQi1S-jl4mo"
   },
   "source": [
    "### More poetic model\n",
    "\n",
    "Let's use LSTM instead of vanilla RNN and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iSrhFn5rYrlt"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokens, device=device, n_hidden=256, n_layers=2, drop_prob=0.5):\n",
    "        super().__init__()    \n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden       \n",
    "        self.n_tokens = len(tokens)\n",
    "        self.idx_to_token = dict((i, c) for i, c in enumerate(tokens))\n",
    "        self.token_to_idx = dict((c, i) for i, c in enumerate(tokens))\n",
    "\n",
    "        self.lstm = nn.LSTM(self.n_tokens, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, self.n_tokens)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)        \n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8vP5b7Ml4mp"
   },
   "source": [
    "Plot the loss function of the number of epochs. Does the final loss become better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "id": "ZWThcHFrl4mo"
   },
   "outputs": [],
   "source": [
    "def train(model, data, device, optimizer, criterion, epochs=20, batch_size=BATCH_SIZE, seq_len=SEQ_LEN, clip=5):\n",
    "    history = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        hid = model.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data, batch_size, seq_len):\n",
    "            # OHE data\n",
    "            x = one_hot_encode(x, model.n_tokens)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()            \n",
    "            output, hid = model(inputs, hid)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = criterion(output, targets.view(batch_size*seq_len).long())\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            # clip gradients to avoid exploding gradients,\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            history.append(loss.item())\n",
    "\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "collapsed": true,
    "id": "SvB_00W6l4mp",
    "outputId": "9849fa6e-e1a9-45e3-b454-f831bf9d4633"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the model\n",
    "n_hidden=512\n",
    "n_layers=2\n",
    "model = LSTM(tokens, device, n_hidden, n_layers).to(device)\n",
    "epochs = 300 \n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train the model\n",
    "train(model, sequence, device, opt, criterion, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
